{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2fc269",
   "metadata": {},
   "source": [
    "# Training DIPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train dipz with keras\n",
    "\"\"\"\n",
    "#'Take only this many inputs (with no args %(const)s)'\n",
    "_h_take_first = 'Take only this many inputs (with no args %(const)s)'\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# local libs\n",
    "from layers import Sum\n",
    "from utils import gaussian_loss\n",
    "from utils import TRANSFORMS\n",
    "from utils import scale\n",
    "from utils import renamed\n",
    "from utils import build_feature\n",
    "from utils import get_gaussian_loss_prec\n",
    "\n",
    "# mlearnin libs\n",
    "import numpy as np\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPU Resources Available:\\n\\t\",gpus)\n",
    "\n",
    "from tensorflow import keras\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import (\n",
    "    Dense, TimeDistributed, Input, Concatenate, Masking\n",
    ")\n",
    "from keras.utils.generic_utils import CustomMaskWarning\n",
    "\n",
    "# the data libs\n",
    "import h5py\n",
    "import json\n",
    "\n",
    "# random python utility libs\n",
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afce0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_FILEPATH = \"./data/data.h5\"\n",
    "DATA_FILEPATH = \"./data/subset.h5\"\n",
    "CONFIG_FILEPATH = \"./regress.json\"\n",
    "\n",
    "# TODO: clean up these hardcoded values\n",
    "MASK_VALUE = 999\n",
    "MERGED_NODES = [32]*4\n",
    "\n",
    "# A function to define and gets the config file \n",
    "def get_config(config_path):\n",
    "    with open(config_path) as cfg:\n",
    "        config = json.load(cfg)\n",
    "    return dict(\n",
    "        jetfeatnames=config[\"jetfeatnames\"],\n",
    "        trackfeatnames=config[\"trackfeatnames\"],\n",
    "        targetfeatnames=config[\"targetfeatnames\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        epoch_size=config[\"epoch_size\"],\n",
    "        number_epochs=config[\"number_epochs\"],\n",
    "        learning_rate=config[\"lr\"],\n",
    "        tracknodes=config['tracknodes'],\n",
    "        jetnodes=config['jetnodes'],\n",
    "    )\n",
    "\n",
    "# A function that defines and gets the neural network model\n",
    "def get_model(config, mask_value):\n",
    "    n_track_inputs = len(config['trackfeatnames'])\n",
    "    track_inputs = Input(shape=(None,n_track_inputs))\n",
    "\n",
    "    n_jet_inputs = len(config['jetfeatnames'])\n",
    "    jet_inputs = Input(shape=(n_jet_inputs))\n",
    "\n",
    "    # add jet layers\n",
    "    x = jet_inputs\n",
    "    for nodes in config['jetnodes']:\n",
    "        x = Dense(units=nodes, activation='relu')(x)\n",
    "    jet_latent = x\n",
    "\n",
    "    # add track layers\n",
    "    x = track_inputs\n",
    "    x = Masking(mask_value=mask_value)(x)\n",
    "    for nodes in config['tracknodes']:\n",
    "        x = TimeDistributed(Dense(nodes, activation='relu'))(x)\n",
    "    x = Sum()(x)\n",
    "    track_latent = x\n",
    "\n",
    "    # merge the layers\n",
    "    merged = Concatenate()([jet_latent, track_latent])\n",
    "    # todo: not clear how many additonal processing layers we should\n",
    "    # add here\n",
    "    x = merged\n",
    "    for nodes in MERGED_NODES:\n",
    "        x = Dense(nodes, activation='relu')(x)\n",
    "    out_latent = x\n",
    "    outputs = keras.layers.Dense(units=2)(out_latent)\n",
    "    model = keras.Model(\n",
    "        inputs=[jet_inputs, track_inputs],\n",
    "        outputs=outputs)\n",
    "    # print the summary\n",
    "    model.summary()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                  loss=gaussian_loss)\n",
    "    return model\n",
    "\n",
    "# A function that imports the dataset we will be working on\n",
    "def get_dataset(h5_filepath, config, mask_value, take_first=False):\n",
    "    \"\"\"\n",
    "    We make some hardcoded transformations to normalize these inputs\n",
    "    \"\"\"\n",
    "\n",
    "    # pt is log transformed\n",
    "    # Z0 is divided by 50\n",
    "    # target is divided by 50\n",
    "\n",
    "    trf = TRANSFORMS\n",
    "    # identy function to pass through things that aren't listed above\n",
    "    def ident(x):\n",
    "        return x\n",
    "\n",
    "    sl = slice(None,None,None)\n",
    "    if take_first:\n",
    "        sl = slice(0,take_first,None)\n",
    "\n",
    "    with h5py.File(h5_filepath) as h5file:\n",
    "        # get track array\n",
    "        [print(item) for item in h5file.items()]\n",
    "        td = h5file['fs_tracks_simple_ip']\n",
    "        tfn = config['trackfeatnames']\n",
    "        # we can pass through NaNs here\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            trackstack = [trf.get(x,ident)(td[x,sl,...]) for x in tfn]\n",
    "        track_array = np.stack(trackstack, axis=2)\n",
    "        invalid = np.isnan(td['pt',sl])\n",
    "        track_array[invalid,:] = mask_value\n",
    "\n",
    "        # get jet array\n",
    "        jd = h5file['jets']\n",
    "        jfn = config['jetfeatnames']\n",
    "        jetstack = [trf.get(x,ident)(jd[x,sl]) for x in jfn]\n",
    "        jet_array = np.stack(jetstack, axis=1)\n",
    "\n",
    "        # get targets\n",
    "        tfn = config['targetfeatnames']\n",
    "        targetstack = [trf.get(x,ident)(jd[x,sl]) for x in tfn]\n",
    "        target_array = np.stack(targetstack, axis=1)\n",
    "\n",
    "    return jet_array, track_array, target_array\n",
    "\n",
    "# A function that gets the inputs to save them\n",
    "def get_inputs(jet_feature_names, track_feature_names):\n",
    "    track_variables = [build_feature(x) for x in track_feature_names]\n",
    "    jet_variables = [build_feature(x) for x in jet_feature_names]\n",
    "    return {\n",
    "        'input_sequences': [\n",
    "            {\n",
    "                'name': 'tracks_loose202102NoIpCuts_absD0DescendingSort',\n",
    "                'variables': track_variables,\n",
    "            }\n",
    "        ],\n",
    "        'inputs': [\n",
    "            {\n",
    "                'name': 'btagging',\n",
    "                'variables': jet_variables\n",
    "            }\n",
    "        ],\n",
    "        'outputs': [\n",
    "            {\n",
    "                'labels': ['z','negLogSigma2'],\n",
    "                'name': 'dipz'\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# A function that saves the model\n",
    "def save_model(model, output_dir, inputs):\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    with open(output_dir / 'architecture.json', 'w') as arch:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore', category=CustomMaskWarning)\n",
    "            arch.write(model.to_json(indent=2))\n",
    "\n",
    "    model.save_weights(output_dir / 'weights.h5')\n",
    "\n",
    "    with open(output_dir / 'inputs.json', 'w') as inputs_file:\n",
    "        json.dump(inputs, inputs_file, indent=2)\n",
    "\n",
    "# A function that runs the neural network training and saves the weights\n",
    "def run(config_filepath, h5_filepath, num_epochs = 10):\n",
    "    mask_value = MASK_VALUE\n",
    "    config = get_config(config_filepath)\n",
    "    model = get_model(config, mask_value=mask_value)\n",
    "    jet_inputs, track_inputs, targets = get_dataset(h5_filepath, config, mask_value)\n",
    "    model.fit([jet_inputs, track_inputs], targets, epochs=num_epochs)\n",
    "    inputs = get_inputs(config['jetfeatnames'], config['trackfeatnames'])\n",
    "    save_model(model, inputs=inputs, output_dir=Path('outputs'))\n",
    "BEGIN = time.time()\n",
    "print(f\"[{datetime.datetime.now().strftime(f'%H:%M:%S')}] Start\", flush=True)\n",
    "\n",
    "run(CONFIG_FILEPATH, DATA_FILEPATH)\n",
    "\n",
    "print(f\"[{datetime.datetime.now().strftime(f'%H:%M:%S')}]\", end=\" \")\n",
    "print(f\"Runtime: {round(time.time() - BEGIN, 3)}s\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
